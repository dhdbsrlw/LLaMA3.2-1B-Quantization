# (1) PPL Evaluation
seed: 42
output_dir: ./result
file_name: ppl_base_llama_1b_bf16

model_path: /nas2/checkpoints/Llama-3.2-1B
model_type: pretrain
tokenizer_path:

device: cuda
# use_bfloat: False
use_bfloat: True # bf16

ckpt:
lora_ckpt:

batch_size: 8
num_workers: 0
max_seq_len: 128


# (2) Example Text Generation
input_prompt: 
num_output: 5
generation_config:  
  do_sample: True
  top_p: 0.95
  top_k: 50
  temperature: 1.0
  max_new_tokens: 2048
